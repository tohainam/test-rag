# K·∫ø Ho·∫°ch Tri·ªÉn Khai H·ªá Th·ªëng ƒê√°nh Gi√° RAGAS cho LTV Assistant

**Phi√™n b·∫£n T√†i li·ªáu:** 5.0
**Ng√†y t·∫°o:** 2025-11-10
**Lo·∫°i T√†i li·ªáu:** Product Requirements Document (PRD)
**Tr·∫°ng th√°i:** Draft
**Ng√¥n ng·ªØ:** Ti·∫øng Vi·ªát

---

## M·ª•c L·ª•c

1. [T·ªïng Quan](#t·ªïng-quan)
2. [Y√™u C·∫ßu Nghi·ªáp V·ª•](#y√™u-c·∫ßu-nghi·ªáp-v·ª•)
3. [Y√™u C·∫ßu Ch·ª©c NƒÉng](#y√™u-c·∫ßu-ch·ª©c-nƒÉng)
4. [Y√™u C·∫ßu Phi Ch·ª©c NƒÉng](#y√™u-c·∫ßu-phi-ch·ª©c-nƒÉng)
5. [Ki·∫øn Tr√∫c H·ªá Th·ªëng](#ki·∫øn-tr√∫c-h·ªá-th·ªëng)
6. [Data Model](#data-model)
7. [User Flows](#user-flows)
8. [UI/UX Requirements](#uiux-requirements)
9. [Integration Points](#integration-points)
10. [Security & Access Control](#security--access-control)
11. [Phases & Milestones](#phases--milestones)
12. [Success Metrics](#success-metrics)
13. [Risks & Mitigations](#risks--mitigations)

---

## T·ªïng Quan

### 1.1 M·ª•c ƒê√≠ch

X√¢y d·ª±ng h·ªá th·ªëng ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng Retrieval System s·ª≠ d·ª•ng framework RAGAS, cho ph√©p Super Admin:
- Upload documents ƒë·ªÉ t·∫°o evaluation datasets
- T·∫°o v√† qu·∫£n l√Ω datasets v·ªõi questions manually ho·∫∑c t·ª± ƒë·ªông b·∫±ng LLM
- Ch·∫°y evaluation tests theo c√°ch tu·∫ßn t·ª± (sequential) ƒë·ªÉ tr√°nh overload
- Theo d√µi progress real-time t·ª´ng c√¢u h·ªèi ƒëang ƒë∆∞·ª£c test
- Xem k·∫øt qu·∫£ evaluation chi ti·∫øt tr√™n dashboard

### 1.2 V·∫•n ƒê·ªÅ C·∫ßn Gi·∫£i Quy·∫øt

**Hi·ªán t·∫°i:**
- Kh√¥ng c√≥ c√°ch ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng Retrieval System
- Kh√¥ng bi·∫øt system perform t·ªët hay x·∫•u v·ªõi c√°c lo·∫°i c√¢u h·ªèi kh√°c nhau
- Kh√¥ng c√≥ baseline ƒë·ªÉ so s√°nh improvements
- M·ªói l·∫ßn ch·∫°y evaluation ph·∫£i t·∫°o dataset m·ªõi t·ªën chi ph√≠ LLM

**Gi·∫£i ph√°p:**
- Framework ƒë√°nh gi√° chu·∫©n v·ªõi RAGAS metrics
- Cho ph√©p t·∫°o datasets c√≥ th·ªÉ t√°i s·ª≠ d·ª•ng
- H·ªó tr·ª£ c·∫£ manual (ti·∫øt ki·ªám) v√† auto-generation (ti·ªán l·ª£i)
- Sequential testing ƒë·ªÉ kh√¥ng l√†m qu√° t·∫£i retrieval service
- Dashboard lu√¥n hi·ªÉn th·ªã k·∫øt qu·∫£ test g·∫ßn nh·∫•t

### 1.3 ƒê·ªëi T∆∞·ª£ng S·ª≠ D·ª•ng

- **Super Admin:** Duy nh·∫•t role ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng to√†n b·ªô evaluation system
- **System:** Retrieval service s·∫Ω ƒë∆∞·ª£c g·ªçi ƒë·ªÉ test

### 1.4 Ph·∫°m Vi Phase 1

**Trong ph·∫°m vi:**
- ‚úÖ Upload files v√†o MinIO bucket "evaluation"
- ‚úÖ CRUD datasets (manual + auto-generated options)
- ‚úÖ CRUD questions trong datasets
- ‚úÖ Sequential evaluation (test t·ª´ng c√¢u m·ªôt)
- ‚úÖ Progress tracking per question
- ‚úÖ Dashboard hi·ªÉn th·ªã last test results
- ‚úÖ RAGAS retrieval metrics: Context Precision, Context Recall, Context Relevancy
- ‚úÖ Super Admin only access

**Ngo√†i ph·∫°m vi:**
- ‚ùå Generation metrics (Faithfulness, Answer Relevancy)
- ‚ùå Scheduled/automated evaluation
- ‚ùå A/B testing features
- ‚ùå Custom metrics definitions
- ‚ùå Multi-user collaboration
- ‚ùå Public API access

---

## Y√™u C·∫ßu Nghi·ªáp V·ª•

### 2.1 Business Goals

1. **ƒêo l∆∞·ªùng ch·∫•t l∆∞·ª£ng Retrieval:** C√≥ c∆° s·ªü ƒë·ªÉ ƒë√°nh gi√° system perform t·ªët hay kh√¥ng
2. **Ti·∫øt ki·ªám chi ph√≠:** Cho ph√©p t·∫°o s·∫µn datasets ƒë·ªÉ t√°i s·ª≠ d·ª•ng, kh√¥ng ph·∫£i generate m·ªói l·∫ßn test
3. **Tr√°nh overload system:** Test tu·∫ßn t·ª± t·ª´ng c√¢u h·ªèi m·ªôt thay v√¨ parallel
4. **Easy monitoring:** Dashboard lu√¥n hi·ªÉn th·ªã k·∫øt qu·∫£ test g·∫ßn nh·∫•t
5. **Baseline cho improvements:** C√≥ d·ªØ li·ªáu l·ªãch s·ª≠ ƒë·ªÉ so s√°nh khi optimize system

### 2.2 Key Use Cases

**UC1: Super Admin t·∫°o dataset manually**
- Upload files ch·ª©a documents c·∫ßn test
- T·ª± vi·∫øt questions v√† expected contexts
- Kh√¥ng t·ªën chi ph√≠ LLM
- Ki·ªÉm so√°t ho√†n to√†n ch·∫•t l∆∞·ª£ng questions

**UC2: Super Admin t·∫°o dataset b·∫±ng LLM (optional)**
- Upload files
- LLM t·ª± ƒë·ªông generate questions t·ª´ file content
- Ti·∫øt ki·ªám th·ªùi gian
- C√≥ th·ªÉ edit questions sau khi generate

**UC3: Super Admin ch·∫°y evaluation**
- Ch·ªçn dataset ƒë√£ c√≥
- Ch·ªçn documents/files li√™n quan
- H·ªá th·ªëng test tu·∫ßn t·ª± t·ª´ng c√¢u m·ªôt
- Xem progress real-time
- Nh·∫≠n k·∫øt qu·∫£ chi ti·∫øt

**UC4: Super Admin xem dashboard**
- T·ª± ƒë·ªông hi·ªÉn th·ªã test g·∫ßn nh·∫•t
- Xem metrics overview
- Xem chi ti·∫øt t·ª´ng c√¢u h·ªèi
- Export results

### 2.3 Business Constraints

- **Budget:** Tr√°nh chi ph√≠ LLM kh√¥ng c·∫ßn thi·∫øt ‚Üí cho ph√©p manual datasets
- **System Load:** Retrieval service kh√¥ng ƒë∆∞·ª£c qu√° t·∫£i ‚Üí sequential testing
- **Security:** Ch·ªâ super admin ‚Üí role-based access control
- **Data Privacy:** Files evaluation ri√™ng bi·ªát v·ªõi production documents ‚Üí bucket "evaluation"

---

## Y√™u C·∫ßu Ch·ª©c NƒÉng

### 3.1 File Management

**FR-FILE-001: Upload Files**
- Super Admin c√≥ th·ªÉ upload files (PDF, DOCX, TXT, MD)
- Max file size: 100MB
- Files l∆∞u v√†o MinIO bucket "evaluation"
- Validation: file type, size
- Response: file_id, presigned URL (optional)

**FR-FILE-002: List Files**
- Hi·ªÉn th·ªã danh s√°ch files ƒë√£ upload
- Pagination support
- Filter by uploaded_by
- Show: filename, size, type, upload date

**FR-FILE-003: Delete Files**
- X√≥a file kh·ªèi MinIO v√† database
- Cascade delete: n·∫øu file ƒëang ƒë∆∞·ª£c d√πng trong dataset, c·∫£nh b√°o

**FR-FILE-004: Download Files**
- Generate presigned download URL
- URL expiry: 1 hour

### 3.2 Dataset Management

**FR-DS-001: Create Dataset**
- Input: name, description, source (manual/llm_generated)
- Link v·ªõi uploaded files
- Source = manual: dataset r·ªóng, admin s·∫Ω th√™m questions sau
- Source = llm_generated: trigger auto-generation

**FR-DS-002: List Datasets**
- Hi·ªÉn th·ªã t·∫•t c·∫£ datasets
- Pagination, sorting, filtering
- Show: name, total_questions, source, created_date, created_by

**FR-DS-003: Get Dataset Details**
- Xem th√¥ng tin dataset
- List t·∫•t c·∫£ questions trong dataset
- Show linked files

**FR-DS-004: Update Dataset**
- S·ª≠a name, description
- KH√îNG cho ph√©p ƒë·ªïi source type sau khi t·∫°o

**FR-DS-005: Delete Dataset**
- X√≥a dataset v√† t·∫•t c·∫£ questions
- Cascade delete evaluation runs s·ª≠ d·ª•ng dataset n√†y
- Confirmation required

### 3.3 Question Management

**FR-Q-001: Add Questions (Bulk)**
- Th√™m nhi·ªÅu questions c√πng l√∫c v√†o dataset
- Input: array of {question, expected_context, metadata}
- Auto-assign order_index cho sequential testing

**FR-Q-002: Update Question**
- S·ª≠a question text
- S·ª≠a expected_context
- S·ª≠a metadata

**FR-Q-003: Delete Question**
- X√≥a single question kh·ªèi dataset
- Re-order c√°c questions c√≤n l·∫°i

**FR-Q-004: Reorder Questions**
- Thay ƒë·ªïi order_index
- Quan tr·ªçng cho sequential testing

### 3.4 LLM Generation (Optional)

**FR-GEN-001: Generate Questions from Files**
- Input: file_ids, questions_per_chunk
- LLM ƒë·ªçc file content v√† generate questions
- Output: dataset v·ªõi auto-generated questions
- User c√≥ th·ªÉ review v√† edit sau

**FR-GEN-002: Chunk Configuration**
- Configurable chunk size (min, max)
- Configurable questions per chunk
- Deduplication logic

### 3.5 Evaluation Execution

**FR-EVAL-001: Create Evaluation Job**
- Input: dataset_id, config (topK, metrics, etc.)
- T·∫°o async job
- Return: job_id
- Queue job v√†o Redis Queue

**FR-EVAL-002: Sequential Testing**
- Test T·ª™NG c√¢u h·ªèi m·ªôt (KH√îNG parallel)
- Loop: for each question in order_index
  - Update current_question_index
  - Update current_question_id
  - Call retrieval service
  - Evaluate with RAGAS
  - Save result immediately
  - Update progress
- Next question ch·ªâ ch·∫°y sau khi question hi·ªán t·∫°i done

**FR-EVAL-003: Progress Tracking**
- Real-time progress update
- Show: "Testing question 35/100"
- Show: current_question_id being tested
- Progress percentage: (current/total) * 100
- Update in Redis cache ƒë·ªÉ CMS poll

**FR-EVAL-004: Error Handling**
- N·∫øu 1 question fail: log error, mark as failed, continue next
- N·∫øu critical error: stop job, mark as failed
- Retry logic: max 3 retries per question

**FR-EVAL-005: Results Storage**
- M·ªói question ‚Üí 1 row trong evaluation_results
- Save: question, retrieved_contexts, expected_context, scores, metadata
- Save timing info: retrieval_time, evaluation_time
- Save cache hit/miss info

### 3.6 Results & Dashboard

**FR-DASH-001: Auto-Load Latest Run**
- Dashboard t·ª± ƒë·ªông query latest evaluation run
- Kh√¥ng c·∫ßn user ch·ªçn run_id
- Query: SELECT * FROM evaluation_runs ORDER BY created_at DESC LIMIT 1

**FR-DASH-002: Metrics Overview**
- Show aggregate metrics:
  - Average scores (precision, recall, relevancy)
  - Min, max, std
  - Total questions, successful, failed
  - Processing time
- Visual: progress bars, badges

**FR-DASH-003: Detailed Results**
- List all questions v·ªõi scores
- Pagination support
- Filter: by score range, by question text
- Sort: by score, by question order
- Show: question, contexts, expected_context, scores

**FR-DASH-004: Question Detail Modal**
- Click v√†o question ‚Üí show detail
- Show: full question text
- Show: all retrieved contexts
- Show: expected context
- Show: RAGAS scores v·ªõi explanation
- Show: metadata (timing, cache hit)

**FR-DASH-005: Export Results**
- Export to CSV
- Export to JSON
- Include all details or summary only

### 3.7 Job Management

**FR-JOB-001: Get Job Status**
- Input: job_id
- Return: status, phase, progress, current_step, error
- Poll interval: 5 seconds

**FR-JOB-002: List Jobs**
- Show job history
- Pagination, filtering by status, date
- Show: job_id, status, progress, created_date

**FR-JOB-003: Cancel Job**
- KH√îNG implement trong Phase 1 (nice to have)

---

## Y√™u C·∫ßu Phi Ch·ª©c NƒÉng

### 4.1 Performance

**NFR-PERF-001: Sequential Testing Performance**
- Test 1 question at a time
- Expected time per question: 2-5 seconds (t√πy retrieval service)
- 100 questions = ~5-10 ph√∫t
- Acceptable ƒë·ªÉ tr√°nh overload

**NFR-PERF-002: File Upload**
- Support up to 100MB files
- Upload time: < 30 seconds cho 10MB file
- Presigned URL option cho large files

**NFR-PERF-003: Dashboard Load Time**
- Dashboard load latest run: < 2 seconds
- Results list (paginated): < 1 second

**NFR-PERF-004: API Response Time**
- List datasets: < 500ms
- List questions: < 1s (pagination)
- Create dataset: < 200ms

### 4.2 Scalability

**NFR-SCALE-001: Dataset Size**
- Support up to 1000 questions per dataset
- Support up to 50 datasets

**NFR-SCALE-002: File Storage**
- MinIO bucket "evaluation": up to 10GB
- ~100 files average

**NFR-SCALE-003: Concurrent Users**
- Phase 1: 1 super admin
- System designed for future multi-user

**NFR-SCALE-004: Job Queue**
- Support up to 10 pending jobs
- 1 worker process jobs sequentially

### 4.3 Reliability

**NFR-REL-001: Job Completion**
- Jobs must complete or fail, kh√¥ng ƒë∆∞·ª£c stuck
- Timeout: 2 hours per job
- Auto-fail n·∫øu exceed timeout

**NFR-REL-002: Data Persistence**
- Partial results saved immediately
- N·∫øu job crash, results ƒë√£ save kh√¥ng b·ªã m·∫•t
- Resume support (nice to have, not Phase 1)

**NFR-REL-003: Error Recovery**
- Retry failed questions up to 3 times
- Log all errors v·ªõi context
- Graceful degradation

### 4.4 Maintainability

**NFR-MAINT-001: Code Organization**
- Follow Python best practices
- Clear separation of concerns
- Feature Sliced Design cho frontend

**NFR-MAINT-002: Logging**
- Structured logging (JSON format)
- Log levels: debug, info, warning, error
- Include context: user_id, job_id, question_id

**NFR-MAINT-003: Configuration**
- Environment-based configuration
- No hardcoded values
- Easy to change settings

### 4.5 Usability

**NFR-USE-001: UI Responsiveness**
- CMS UI responsive v·ªõi Mantine components
- Real-time progress updates (poll every 5s)
- Clear feedback messages

**NFR-USE-002: Error Messages**
- User-friendly error messages
- Actionable guidance
- No technical jargon in UI

**NFR-USE-003: Help & Documentation**
- Tooltips for complex features
- In-app help text
- README documentation

---

## Ki·∫øn Tr√∫c H·ªá Th·ªëng

### 5.1 T·ªïng Quan Architecture

**Microservices Pattern:**
- **ltv-ragas-evaluation:** Python Flask service ƒë·ªôc l·∫≠p
- **RQ Worker:** Background job processor
- **API Gateway:** Proxy v√† authentication
- **CMS:** React frontend

**Characteristics:**
- Stateless service
- Direct database access (MySQL, Redis, MinIO)
- Async job processing
- RESTful API

### 5.2 System Components

```mermaid
graph TB
    CMS[CMS - React/Mantine<br/>Super Admin UI] -->|HTTPS| Gateway[API Gateway<br/>Auth & Proxy]
    Gateway -->|/evaluation/*| Flask[RAGAS Service<br/>Python Flask]

    Flask -->|Queue Jobs| Redis[(Redis<br/>Job Queue)]
    Flask -->|Store Data| MySQL[(MySQL<br/>Datasets & Results)]
    Flask -->|Upload/Download| MinIO[(MinIO<br/>evaluation bucket)]

    Worker[RQ Worker<br/>Sequential Processing] -->|Process| Redis
    Worker -->|Test| Retrieval[Retrieval Service]
    Worker -->|Save Results| MySQL

    Flask -.Optional.-> LLM[LLM Provider<br/>Question Generation]

    style CMS fill:#e1f5ff
    style Flask fill:#f3e5f5
    style Worker fill:#fff9c4
```

### 5.3 Technology Stack

**Backend:**
- Python 3.11+
- Flask (web framework)
- SQLAlchemy (ORM)
- Redis Queue (async jobs)
- RAGAS 0.3.8 (evaluation framework)
- MinIO client (file storage)

**Frontend:**
- React 19
- Mantine UI 8.3
- React Query (data fetching)
- React Router (routing)

**Infrastructure:**
- Docker & Docker Compose
- MySQL 8.0
- Redis 7
- MinIO (S3-compatible)

**Optional:**
- Ollama / OpenAI / Anthropic (LLM providers)

### 5.4 Data Flow

**Upload Flow:**
```
User Upload File ‚Üí API Gateway ‚Üí Flask ‚Üí MinIO (store) + MySQL (metadata)
```

**Create Dataset Flow:**
```
User Create Dataset ‚Üí API Gateway ‚Üí Flask ‚Üí MySQL (dataset record)
User Add Questions ‚Üí API Gateway ‚Üí Flask ‚Üí MySQL (questions with order_index)
```

**Evaluation Flow:**
```
User Start Eval ‚Üí Flask ‚Üí Create Job ‚Üí Redis Queue
RQ Worker ‚Üí Get Job ‚Üí Load Dataset ‚Üí Loop Questions:
  For each question (sequential):
    - Update progress
    - Call Retrieval Service
    - RAGAS evaluate
    - Save result to MySQL
    - Update Redis cache
```

**Dashboard Flow:**
```
User Open Dashboard ‚Üí Query latest run ‚Üí MySQL ‚Üí Return results ‚Üí Display
```

---

## Data Model

### 6.1 Core Entities

**EvaluationFile:**
- file_id (PK)
- filename, original_filename
- content_type, filesize
- minio_bucket, minio_object_name
- uploaded_by_user_id
- created_at, updated_at

**EvaluationDataset:**
- dataset_id (PK)
- name, description
- source (manual | llm_generated)
- config (JSON)
- total_questions
- created_by_user_id
- created_at, updated_at

**DatasetQuestion:**
- question_id (PK)
- dataset_id (FK)
- question (TEXT)
- expected_context (TEXT)
- order_index (INT) ‚Üê Important for sequential
- metadata (JSON)
- created_at, updated_at

**EvaluationRun:**
- run_id (PK)
- dataset_id (FK)
- job_id (FK to EvaluationJob)
- status (pending | running | completed | failed)
- config (JSON)
- total_questions, successful_questions, failed_questions
- **current_question_index (INT)** ‚Üê Track current position
- **current_question_id** ‚Üê Track which question testing
- average_scores (JSON)
- statistics (JSON)
- processing_time_ms
- created_at, completed_at

**EvaluationResult:**
- result_id (PK)
- run_id (FK)
- question_id (FK)
- question (TEXT)
- retrieved_contexts (JSON array)
- expected_context (TEXT)
- context_precision (FLOAT)
- context_recall (FLOAT)
- context_relevancy (FLOAT)
- metadata (JSON: timing, cache_hit)
- created_at

**EvaluationJob:**
- job_id (PK)
- status (pending | processing | completed | failed)
- phase (validating | loading_dataset | testing_questions | calculating_stats)
- progress_percent (INT)
- **current_step (VARCHAR: "Testing question 35/100")** ‚Üê For display
- config (JSON)
- created_by_user_id
- error_message
- created_at, started_at, completed_at

### 6.2 Relationships

```
EvaluationDataset 1 ‚îÄ‚îÄ‚îÄ N DatasetQuestion
EvaluationDataset 1 ‚îÄ‚îÄ‚îÄ N EvaluationRun
EvaluationRun 1 ‚îÄ‚îÄ‚îÄ N EvaluationResult
EvaluationJob 1 ‚îÄ‚îÄ‚îÄ 1 EvaluationRun
EvaluationDataset N ‚îÄ‚îÄ‚îÄ N EvaluationFile (many-to-many)
```

### 6.3 Indexes

**Key Indexes:**
- dataset_id, question_id, run_id, job_id
- order_index (for sequential ordering)
- current_question_index (for progress tracking)
- created_at (for latest run query)
- status (for filtering)

---

## User Flows

### 7.1 Create Manual Dataset Flow

```
1. Super Admin clicks "New Dataset"
2. Fill form: name, description
3. Select source: "Manual"
4. Upload files (optional, for reference)
5. Submit ‚Üí dataset created
6. Navigate to "Add Questions"
7. Bulk input questions:
   - Question text
   - Expected context
   - Metadata (optional)
8. Submit ‚Üí questions saved v·ªõi order_index auto-assigned
9. Done ‚Üí dataset ready for evaluation
```

### 7.2 Create Auto-Generated Dataset Flow

```
1. Super Admin clicks "New Dataset"
2. Fill form: name, description
3. Select source: "LLM Generated"
4. Upload files (required)
5. Configure: questions_per_chunk
6. Submit ‚Üí async job created
7. Wait for generation (poll progress)
8. Review generated questions
9. Edit/delete questions if needed
10. Done ‚Üí dataset ready for evaluation
```

### 7.3 Run Evaluation Flow

```
1. Super Admin clicks "Run Evaluation"
2. Select dataset t·ª´ dropdown
3. Configure:
   - retrieval_top_k
   - metrics (default: all)
4. Submit ‚Üí job created
5. Redirect to "Job Status" page
6. Poll progress every 5 seconds:
   - Show progress bar
   - Show current_step: "Testing question 35/100"
   - Show estimated time remaining
7. When completed ‚Üí redirect to results
8. Or click "View Dashboard" ‚Üí auto-show this run
```

### 7.4 View Results Flow

```
1. Super Admin opens "Evaluation Dashboard"
2. System auto-loads latest run
3. Display:
   - Metrics overview (cards with scores)
   - Progress summary
   - Questions list (paginated)
4. Click on a question ‚Üí modal opens:
   - Full question text
   - Retrieved contexts (all 10)
   - Expected context
   - RAGAS scores
   - Metadata
5. Export button ‚Üí download CSV/JSON
6. Select different run (optional) ‚Üí dropdown
```

---

## UI/UX Requirements

### 8.1 Page Structure

**Pages:**
1. **Files Management** - Upload, list, delete files
2. **Datasets** - CRUD datasets
3. **Questions** - View and edit questions in dataset
4. **Evaluation Dashboard** - Main page, auto-show last test
5. **Job History** - List all evaluation jobs
6. **Run Evaluation** - Form to start new evaluation

### 8.2 Files Management Page

**Layout:**
```
‚îå‚îÄ Files Management ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  [+ Upload Files]                      [Filter ‚ñº]      ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ Uploaded Files ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Filename ‚îÇ Type   ‚îÇ Size     ‚îÇ Date ‚îÇ Actions‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ doc1.pdf ‚îÇ PDF    ‚îÇ 2.5 MB   ‚îÇ ...  ‚îÇ üëÅÔ∏è üóëÔ∏è  ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ doc2.txt ‚îÇ TXT    ‚îÇ 150 KB   ‚îÇ ...  ‚îÇ üëÅÔ∏è üóëÔ∏è  ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Features:**
- Dropzone for drag-and-drop upload
- File type validation
- Progress bar during upload
- Preview file metadata
- Delete confirmation

### 8.3 Datasets Page

**Layout:**
```
‚îå‚îÄ Datasets ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  [+ New Dataset]                   [Filter ‚ñº]          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ Dataset List ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Name     ‚îÇ Source  ‚îÇ Questions‚îÇ Actions      ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Test Set ‚îÇ Manual  ‚îÇ 50       ‚îÇ üëÅÔ∏è ‚úèÔ∏è ‚ñ∂Ô∏è üóëÔ∏è ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Auto Gen ‚îÇ LLM     ‚îÇ 120      ‚îÇ üëÅÔ∏è ‚úèÔ∏è ‚ñ∂Ô∏è üóëÔ∏è ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Actions:**
- üëÅÔ∏è View: Xem questions trong dataset
- ‚úèÔ∏è Edit: S·ª≠a name, description
- ‚ñ∂Ô∏è Run: Start evaluation v·ªõi dataset n√†y
- üóëÔ∏è Delete: X√≥a dataset

### 8.4 Evaluation Dashboard (Main Focus)

**Layout - Auto-Show Last Test:**
```
‚îå‚îÄ Evaluation Dashboard ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ  üèÜ Latest Evaluation Results                          ‚îÇ
‚îÇ  Run ID: abc-123 | Dataset: Test Set | Date: 10/11    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ Metrics Overview ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  üì¶ Total: 100    ‚úÖ Success: 95    ‚ùå Failed: 5 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚è±Ô∏è Time: 8m 32s                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Context Precision:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë  85.2%  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Context Recall:      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë  78.4%  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Context Relevancy:   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  92.1%  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Overall Score: 85.2% üü¢                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  [üìä View All Runs] [üíæ Export CSV] [üìÑ Export JSON]  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ Detailed Results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  üîç [Search questions...]                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Question               ‚îÇ Prec‚îÇRecall‚îÇRelev ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ What is JWT auth?      ‚îÇ 92% ‚îÇ 85%  ‚îÇ 95%  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ How does OAuth work?   ‚îÇ 78% ‚îÇ 72%  ‚îÇ 88%  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ...                    ‚îÇ ... ‚îÇ ...  ‚îÇ ...  ‚îÇ ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  [‚óÄ Previous]  Page 1 of 10  [Next ‚ñ∂]           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Features:**
- Auto-load latest run (kh√¥ng c·∫ßn ch·ªçn)
- Metrics cards v·ªõi progress bars
- Color-coded scores: üü¢ >80%, üü° 60-80%, üî¥ <60%
- Click question ‚Üí modal chi ti·∫øt
- Filter v√† search trong results
- Export functionality

### 8.5 Run Evaluation Page

**Layout:**
```
‚îå‚îÄ Run Evaluation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ  Select Dataset:  [Choose dataset ‚ñº]                   ‚îÇ
‚îÇ  ‚Üí Test Set (50 questions)                             ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Configuration:                                         ‚îÇ
‚îÇ  Retrieval Top K:     [10        ]                     ‚îÇ
‚îÇ  Metrics:             [‚úì All Metrics]                  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  [‚ñ∂Ô∏è Start Evaluation]                [Cancel]         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**After Start:**
```
‚îå‚îÄ Evaluation Progress ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                         ‚îÇ
‚îÇ  Job ID: xyz-789                                        ‚îÇ
‚îÇ  Status: ‚è≥ Processing                                 ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Phase: Testing Questions (65%)                        ‚îÇ
‚îÇ  [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 65%               ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Current Step: Testing question 65/100                 ‚îÇ
‚îÇ  Question: "What is token refresh mechanism?"          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Estimated Time Remaining: ~3 minutes                  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  [üîÑ Refresh Status (auto: 5s)]                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 8.6 UI Components

**Reusable Components:**
- FileUploader (Dropzone)
- DatasetCard
- QuestionList
- MetricsCard
- ProgressBar
- ResultsTable
- QuestionDetailModal
- StatusBadge

**Design System:**
- Mantine UI components
- Color scheme: Blue (primary), Green (success), Red (error), Yellow (warning)
- Typography: System font stack
- Spacing: 8px grid
- Responsive: Mobile-friendly

---

## Integration Points

### 9.1 API Gateway Integration

**Path Routing:**
- `/evaluation/*` ‚Üí proxy to ltv-ragas-evaluation:50059
- Gateway handles authentication
- Gateway forwards user headers: X-User-Id, X-User-Email, X-User-Role

**Role Check:**
- Gateway checks if X-User-Role === "super_admin"
- If not, return 403 Forbidden
- If yes, forward request to evaluation service

**CORS:**
- Allow origins: CMS domain
- Allow methods: GET, POST, PUT, DELETE
- Allow headers: Content-Type, Authorization

### 9.2 Retrieval Service Integration

**Endpoint Called:**
- POST /query

**Request:**
```json
{
  "query": "What is JWT authentication?",
  "topK": 10,
  "mode": "retrieval_only",
  "useCache": false
}
```

**Response:**
```json
{
  "contexts": [
    {"content": "...", "score": 0.95, "source": "..."},
    ...
  ],
  "metrics": {
    "totalDuration": 234,
    "cacheHit": false
  }
}
```

**Error Handling:**
- Timeout: 60 seconds
- Retry: 3 times with exponential backoff
- On failure: log error, mark question as failed, continue next

### 9.3 MinIO Integration

**Bucket:** evaluation

**Operations:**
- PUT: Upload file
- GET: Download file
- DELETE: Remove file
- Presigned URLs: For client-side upload/download

**Security:**
- Private bucket
- Only service c√≥ access key
- Presigned URLs c√≥ expiry (1 hour)

### 9.4 Database Integration

**MySQL:**
- Direct connection from service
- Connection pooling (10-20 connections)
- Transactions cho atomic operations
- Migrations v·ªõi Alembic

**Redis:**
- Job queue (RQ)
- Cache cho job status
- Cache cho latest run ID
- TTL: 7 days for job status, no expiry for latest run

---

## Security & Access Control

### 10.1 Authentication

**Flow:**
1. User login qua Auth Service
2. Receive JWT token
3. CMS sends token trong Authorization header
4. API Gateway validates token v·ªõi Auth Service
5. If valid + role = super_admin ‚Üí forward to Evaluation Service
6. Evaluation Service trusts Gateway headers

**Headers:**
- X-Gateway-Auth: "verified"
- X-User-Id: "user-uuid"
- X-User-Email: "admin@example.com"
- X-User-Role: "super_admin"

### 10.2 Authorization

**Role-Based Access:**
- Only "super_admin" role can access ALL evaluation endpoints
- Other roles ‚Üí 403 Forbidden
- Check at API Gateway level
- Double-check at service level (defense in depth)

**Endpoint Protection:**
- ALL /evaluation/* endpoints require super_admin
- No public endpoints
- No API key access (Phase 1)

### 10.3 Data Security

**Files:**
- Encrypted at rest (MinIO encryption)
- Private bucket
- Presigned URLs v·ªõi expiry
- No direct public access

**Database:**
- Encrypted connections (TLS)
- Strong passwords
- Least privilege principle
- Regular backups

**Secrets:**
- Environment variables
- No hardcoded credentials
- Docker secrets (production)

### 10.4 API Security

**Rate Limiting:**
- Phase 1: Not implemented
- Future: 100 requests/minute per user

**Input Validation:**
- File type whitelist
- File size limits
- SQL injection prevention (ORM)
- XSS prevention (React auto-escape)

**CORS:**
- Strict origin control
- No wildcard (*)

---

## Phases & Milestones

### 11.1 Phase 1: Core Features (6-8 weeks)

**Week 1-2: Foundation**
- [ ] Setup project structure
- [ ] Database schema
- [ ] MinIO bucket setup
- [ ] Flask app skeleton
- [ ] API Gateway proxy
- [ ] Role-based middleware

**Week 3-4: File & Dataset Management**
- [ ] File upload API
- [ ] File list/delete API
- [ ] Dataset CRUD API
- [ ] Question CRUD API
- [ ] CMS: Files page
- [ ] CMS: Datasets page

**Week 5-6: Evaluation Engine**
- [ ] RAGAS evaluator setup
- [ ] Sequential job processing
- [ ] Progress tracking
- [ ] Results storage
- [ ] RQ worker
- [ ] Retrieval client

**Week 7-8: Dashboard & Polish**
- [ ] Dashboard v·ªõi auto-load latest
- [ ] Results display
- [ ] Question detail modal
- [ ] Export functionality
- [ ] Testing
- [ ] Bug fixes

**Deliverables:**
- Working evaluation system
- Super admin can upload files
- Super admin can create manual datasets
- Super admin can run sequential evaluations
- Dashboard shows last test results

### 11.2 Phase 2: LLM Generation (Optional, 2-3 weeks)

**If Needed:**
- [ ] LLM integration (Ollama/OpenAI)
- [ ] Prompts for question generation
- [ ] File text extraction (PDF, DOCX)
- [ ] Auto-generation workflow
- [ ] Review/edit UI

### 11.3 Phase 3: Enhancements (Future)

**Not in Current Scope:**
- Multi-user support
- Scheduled evaluations
- A/B testing
- Custom metrics
- Advanced analytics
- Generation metrics

---

## Success Metrics

### 12.1 Technical Metrics

**System Performance:**
- File upload success rate: >99%
- Evaluation completion rate: >95%
- Average evaluation time: <10 minutes for 100 questions
- Dashboard load time: <2 seconds
- API response time: <500ms (p95)

**Reliability:**
- Service uptime: >99%
- Job success rate: >95%
- Data loss: 0%

### 12.2 Business Metrics

**Usage:**
- Number of datasets created: Track monthly
- Number of evaluations run: Track monthly
- Average questions per dataset: Target 50-100
- Reuse rate: % of evaluations using existing datasets

**Value:**
- Time saved: Manual evaluation vs automated
- Cost saved: Reusing datasets vs generating new
- Quality improvement: Track retrieval scores over time

### 12.3 User Satisfaction

**Qualitative:**
- Super admin feedback: Survey
- Feature requests: Backlog
- Bug reports: Track v√† resolve

**Quantitative:**
- Time to create dataset: <10 minutes
- Time to run evaluation: <15 minutes for 100 questions
- Time to view results: <1 minute

---

## Risks & Mitigations

### 13.1 Technical Risks

**Risk 1: Sequential Testing Too Slow**
- Impact: HIGH
- Probability: MEDIUM
- Mitigation:
  - Optimize retrieval service
  - Cache frequently tested questions
  - Parallel future consideration v·ªõi rate limiting
  - Progress tracking ƒë·ªÉ user kh√¥ng frustrated

**Risk 2: MinIO Storage Full**
- Impact: MEDIUM
- Probability: LOW
- Mitigation:
  - Monitor storage usage
  - Implement file size limits
  - Cleanup old/unused files
  - Lifecycle policies

**Risk 3: Job Queue Bottleneck**
- Impact: MEDIUM
- Probability: LOW
- Mitigation:
  - Single super admin (low concurrency)
  - Queue monitoring
  - Job timeout protection
  - Scale worker if needed

**Risk 4: RAGAS Evaluation Errors**
- Impact: HIGH
- Probability: MEDIUM
- Mitigation:
  - Comprehensive error handling
  - Retry logic
  - Fallback metrics
  - Save partial results

### 13.2 Business Risks

**Risk 1: Low Adoption**
- Impact: HIGH
- Probability: LOW
- Mitigation:
  - Clear value proposition
  - Easy onboarding
  - Good documentation
  - Training sessions

**Risk 2: High LLM Costs (if using auto-generation)**
- Impact: MEDIUM
- Probability: MEDIUM
- Mitigation:
  - Make auto-generation optional
  - Encourage manual datasets
  - Use local LLM (Ollama)
  - Monitor usage

**Risk 3: Retrieval Service Overload**
- Impact: HIGH
- Probability: MEDIUM
- Mitigation:
  - Sequential testing (primary mitigation)
  - Run evaluations during low-traffic hours
  - Rate limiting
  - Dedicated evaluation endpoint

### 13.3 Security Risks

**Risk 1: Unauthorized Access**
- Impact: HIGH
- Probability: LOW
- Mitigation:
  - Role-based access control
  - API Gateway authentication
  - Audit logging
  - Regular security reviews

**Risk 2: File Upload Abuse**
- Impact: MEDIUM
- Probability: LOW
- Mitigation:
  - File type whitelist
  - Size limits
  - Virus scanning (future)
  - Super admin only access

---

## Appendix

### A. Glossary

- **RAGAS:** Retrieval-Augmented Generation Assessment framework
- **Context Precision:** T·ª∑ l·ªá contexts relevant trong t·ªïng s·ªë contexts retrieved
- **Context Recall:** T·ª∑ l·ªá ground truth ƒë∆∞·ª£c cover b·ªüi retrieved contexts
- **Context Relevancy:** M·ª©c ƒë·ªô contexts li√™n quan ƒë·∫øn query
- **Sequential Testing:** Test t·ª´ng item m·ªôt, kh√¥ng parallel
- **Super Admin:** Role duy nh·∫•t ƒë∆∞·ª£c access evaluation system
- **Dataset:** T·∫≠p h·ª£p questions ƒë·ªÉ ƒë√°nh gi√°
- **Evaluation Run:** M·ªôt l·∫ßn ch·∫°y evaluation v·ªõi m·ªôt dataset

### B. References

- RAGAS Documentation: https://docs.ragas.io/
- Mantine UI: https://mantine.dev/
- Flask Documentation: https://flask.palletsprojects.com/
- MinIO Python SDK: https://min.io/docs/minio/linux/developers/python/minio-py.html

### C. Contact & Support

- Product Owner: [Name]
- Tech Lead: [Name]
- Questions: [Email/Slack]

---

**END OF DOCUMENT**

**Next Steps:**
1. Review v√† approval t·ª´ stakeholders
2. Technical design document (n·∫øu c·∫ßn chi ti·∫øt implementation)
3. Story breakdown cho development
4. Sprint planning

